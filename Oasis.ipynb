{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4ca118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25151 images belonging to 4 classes.\n",
      "Found 6286 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 25151, Validation samples: 6286\n",
      "Successfully loaded pre-trained model from: C:\\Users\\shrir\\Music\\New folder\\hello_new_cnn_model.h5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">826,726</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m826,726\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">826,724</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m826,724\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrir\\.conda\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Moderate Dementia (Confidence: 0.92)\n",
      "\n",
      "--- Calculating Performance Metrics ---\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IoU</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mild Dementia</th>\n",
       "      <td>0.134858</td>\n",
       "      <td>0.237665</td>\n",
       "      <td>0.389522</td>\n",
       "      <td>0.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate Dementia</th>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.914573</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.938144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non Demented</th>\n",
       "      <td>0.454395</td>\n",
       "      <td>0.624858</td>\n",
       "      <td>0.478858</td>\n",
       "      <td>0.898936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very mild Dementia</th>\n",
       "      <td>0.178852</td>\n",
       "      <td>0.303434</td>\n",
       "      <td>0.511668</td>\n",
       "      <td>0.215665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro/Mean</th>\n",
       "      <td>0.402674</td>\n",
       "      <td>0.520132</td>\n",
       "      <td>0.568051</td>\n",
       "      <td>0.555936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <td>0.485364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         IoU        F1  Precision    Recall\n",
       "Mild Dementia       0.134858  0.237665   0.389522  0.171000\n",
       "Moderate Dementia   0.842593  0.914573   0.892157  0.938144\n",
       "Non Demented        0.454395  0.624858   0.478858  0.898936\n",
       "Very mild Dementia  0.178852  0.303434   0.511668  0.215665\n",
       "Macro/Mean          0.402674  0.520132   0.568051  0.555936\n",
       "Overall Accuracy    0.485364       NaN        NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance metrics table and line plot generated successfully.\n",
      "The plots are saved as 'per_class_metrics_line_plot.png'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model # Import load_model\n",
    "from sklearn.metrics import jaccard_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Section 1: Data Loading and Preprocessing ---\n",
    "# Path to the data directory\n",
    "data_dir = r\"C:\\Users\\shrir\\Music\\New folder\\Data\"\n",
    "\n",
    "# Parameters\n",
    "# IMPORTANT FIX: Changed img_height, img_width to 128 to match model's expected input\n",
    "img_height, img_width = 128, 128\n",
    "batch_size = 32\n",
    "\n",
    "# Data generators (still needed to get class information for metrics calculation)\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True # Shuffle for training\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False # Do NOT shuffle validation set for consistent metrics calculation\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {train_gen.samples}, Validation samples: {val_gen.samples}\")\n",
    "\n",
    "# --- Section 2: Load Pre-trained CNN Model ---\n",
    "# Path to your saved .h5 model\n",
    "model_path = r\"C:\\Users\\shrir\\Music\\New folder\\hello_new_cnn_model.h5\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(f\"Successfully loaded pre-trained model from: {model_path}\")\n",
    "    model.summary() # Display summary of the loaded model\n",
    "else:\n",
    "    print(f\"Error: Model not found at {model_path}. Please ensure the path is correct.\")\n",
    "    exit() # Exit if the model cannot be loaded\n",
    "\n",
    "\n",
    "# --- Section 3: Prediction on a Single Image (Example) ---\n",
    "def predict_image(img_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found at: {img_path}. Skipping prediction example.\")\n",
    "        return\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # The ValueError should be resolved by the img_height/width fix\n",
    "    pred_probs = model.predict(img_array)\n",
    "    pred_class_idx = np.argmax(pred_probs, axis=1)[0]\n",
    "    idx_to_class = {v: k for k, v in train_gen.class_indices.items()}\n",
    "    predicted_label = idx_to_class[pred_class_idx]\n",
    "    confidence = pred_probs[0][pred_class_idx]\n",
    "\n",
    "    print(f\"Predicted: {predicted_label} (Confidence: {confidence:.2f})\")\n",
    "    return predicted_label, confidence\n",
    "\n",
    "# Example usage (ensure this path is correct and accessible on your system)\n",
    "sample_image_path = r\"C:\\Users\\shrir\\Music\\New folder\\Data\\Moderate Dementia\\OAS1_0308_MR1_mpr-1_100.jpg\"\n",
    "predict_image(sample_image_path)\n",
    "\n",
    "# --- Section 4: Metrics Calculation and Plotting ---\n",
    "\n",
    "print(\"\\n--- Calculating Performance Metrics ---\")\n",
    "\n",
    "# Get predictions and true labels from the validation generator\n",
    "val_gen.reset() # Reset generator to ensure predictions start from the beginning\n",
    "y_pred_probs = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# True labels (integer class indices)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "# Number of classes\n",
    "num_classes = y_pred_probs.shape[1]\n",
    "class_names = list(val_gen.class_indices.keys())\n",
    "\n",
    "# Per-class metrics\n",
    "iou_per_class = jaccard_score(y_true, y_pred, average=None, labels=range(num_classes))\n",
    "f1_per_class = f1_score(y_true, y_pred, average=None, labels=range(num_classes), zero_division=0)\n",
    "precision_per_class = precision_score(y_true, y_pred, average=None, labels=range(num_classes), zero_division=0)\n",
    "recall_per_class = recall_score(y_true, y_pred, average=None, labels=range(num_classes), zero_division=0)\n",
    "\n",
    "# Macro metrics (average across classes)\n",
    "miou = jaccard_score(y_true, y_pred, average='macro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "overall_accuracy = accuracy_score(y_true, y_pred) # Renamed from pixel_acc for clarity in classification\n",
    "\n",
    "# Build metrics table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'IoU': iou_per_class,\n",
    "    'F1': f1_per_class,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class\n",
    "}, index=class_names)\n",
    "\n",
    "# Add macro/mean row\n",
    "metrics_df.loc['Macro/Mean'] = [miou, f1_macro, precision_macro, recall_macro]\n",
    "\n",
    "# Add overall accuracy as a separate row\n",
    "metrics_df.loc['Overall Accuracy'] = [overall_accuracy, np.nan, np.nan, np.nan]\n",
    "\n",
    "# Display table\n",
    "display(metrics_df)\n",
    "\n",
    "# Plot line graph for per-class metrics\n",
    "metrics_df.iloc[:-2].plot(marker='o', figsize=(10, 6))\n",
    "plt.title('Per-Class Classification Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1) # Metrics like F1, Precision, Recall are typically between 0 and 1\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_metrics_line_plot.png')\n",
    "plt.close() # Close the plot to free memory\n",
    "\n",
    "print(\"\\nPerformance metrics table and line plot generated successfully.\")\n",
    "print(\"The plots are saved as 'per_class_metrics_line_plot.png'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6cedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Env (Python 3.11)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
